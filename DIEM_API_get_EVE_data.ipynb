{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying period_number: 28\n",
      "No data for period_number: 28, trying previous period...\n",
      "Trying period_number: 27\n",
      "Data found for period_number: 27\n",
      "Saved data as CSV: C:\\temp\\filtered_data_BGD_Period_#27_(01-02-2025_to_15-02-2025)_20250221120804.csv\n",
      "Process completed.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "########################################################################################\n",
    "# FAO - Events Visualization in Emergencies (EVE) - Data Extraction Script\n",
    "########################################################################################\n",
    "\n",
    "# Description:\n",
    "This script programmatically downloads subsets of the EVE (Events Visualization in \n",
    "Emergencies) feature table hosted on ArcGIS Online (AGOL). It enables users to filter \n",
    "data by country and period, dynamically determine the most recent available period, \n",
    "and save the extracted data in either CSV or Excel format.\n",
    "\n",
    "# Functionality:\n",
    "- Connects to ArcGIS Online (AGOL) and retrieves flood monitoring data from EVE.\n",
    "- Allows filtering by:\n",
    "  - Country (`iso3`): Select a specific country using its ISO3 code or retrieve data \n",
    "    for all available countries.\n",
    "  - Period (`period_number`):\n",
    "    - `None`: Retrieve data for **all periods**.\n",
    "    - An **integer**: Retrieve data for a **specific period**.\n",
    "    - `\"latest\"`: Retrieve data for the **most recent available period**.\n",
    "      - The latest period is dynamically determined based on FAO's period numbering \n",
    "        (two periods per month, starting from January 1, 2024).\n",
    "      - If data for the expected latest period is unavailable, the script automatically \n",
    "        checks previous periods until it finds data.\n",
    "- Excludes the `ObjectId` field from the extracted data.\n",
    "- Outputs the data in **CSV** or **Excel** format with a meaningful filename.\n",
    "- Saves the extracted data to a specified output folder.\n",
    "\n",
    "# Output:\n",
    "- The script saves the output file in the specified folder (`output_location`).\n",
    "- The output filename follows the format:\n",
    "  - If a period is selected: `filtered_data_<iso3>_<biweekly_group>_<timestamp>.csv`\n",
    "  - If all periods are selected: `filtered_data_<iso3>_allperiods_<timestamp>.csv`\n",
    "  - Example:\n",
    "    - `filtered_data_BGD_Period_#27_(01-02-2025_to_15-02-2025)_20250221.csv`\n",
    "    - `filtered_data_allcountries_allperiods_20250221.csv`\n",
    "\n",
    "# About the FAO - Events Visualization in Emergencies (EVE) Tool:\n",
    "- EVE is an FAO tool for **flood monitoring and analysis**, providing insights into \n",
    "  flood-affected areas and populations.\n",
    "- Data outputs from EVE can be explored on the official dashboard:\n",
    "  ðŸ“Œ **Dashboard:** https://data-in-emergencies.fao.org/apps/22e659f381fa41e5af05a67db001ac26/explore\n",
    "- Additional information about the EVE system is available here:\n",
    "  ðŸ“Œ **More Info:** https://data-in-emergencies.fao.org/pages/diem_eve\n",
    "\n",
    "# Requirements:\n",
    "- A **DIEM Account** is required to access and download data.  \n",
    "  ðŸ“Œ **Register for a DIEM Account:** https://data-in-emergencies.fao.org/\n",
    "\n",
    "########################################################################################\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import os\n",
    "import datetime\n",
    "from arcgis.gis import GIS\n",
    "import pandas as pd\n",
    "\n",
    "### USER DEFINED PARAMETERS \n",
    "USERNAME = ''  # Your DIEM username\n",
    "PASS = ''  # Your DIEM password\n",
    "# Output location (folder where the files will be saved)\n",
    "output_location = r'C:\\temp'  # Change this to your preferred location\n",
    "# Data filters\n",
    "iso3 = 'BGD'  # Set to desired ISO3 country code or leave empty for all EVE countries\n",
    "period_number = \"latest\"  # Set to desired period number, None for all periods, or \"latest\" for the most recent available\n",
    "file_format = 'CSV'  # Choose between 'CSV' or 'Excel'\n",
    "\n",
    "# Get the current date and time\n",
    "current_datetime = datetime.datetime.now()\n",
    "formatted_datetime = current_datetime.strftime(\"%Y%m%d%H%M%S\")\n",
    "\n",
    "# Calculate the latest period number dynamically\n",
    "def calculate_current_period():\n",
    "    start_year = 2024\n",
    "    current_year = current_datetime.year\n",
    "    current_month = current_datetime.month\n",
    "\n",
    "    # Each year has 24 periods (2 per month)\n",
    "    total_periods_since_start = (current_year - start_year) * 24 + (current_month - 1) * 2\n",
    "\n",
    "    # Determine if we are in the first or second period of the current month\n",
    "    if current_datetime.day >= 15:\n",
    "        total_periods_since_start += 2  # Second period of the month\n",
    "    else:\n",
    "        total_periods_since_start += 1  # First period of the month\n",
    "\n",
    "    return total_periods_since_start\n",
    "\n",
    "\n",
    "# Feature table ID\n",
    "FEATURE_TABLE_ID = '98265cbe82e344f88552d4c2d3615c3c'\n",
    "\n",
    "# Initialize the where clause\n",
    "where_clauses = []\n",
    "if iso3:\n",
    "    where_clauses.append(f\"adm0_iso3 = '{iso3}'\")\n",
    "\n",
    "# Connect to AGOL\n",
    "gis = GIS('https://hqfao-hub.maps.arcgis.com', USERNAME, PASS)\n",
    "\n",
    "# Get the feature layer\n",
    "item = gis.content.get(FEATURE_TABLE_ID)\n",
    "if not item:\n",
    "    raise ValueError(\"Feature table not found. Check the ID.\")\n",
    "\n",
    "feature_layer = item.tables[0]\n",
    "\n",
    "# Determine the period to query\n",
    "if period_number == \"latest\":\n",
    "    period_number = calculate_current_period()\n",
    "    while True:\n",
    "        print(f\"Trying period_number: {period_number}\")\n",
    "        query_result = feature_layer.query(where=f\"period_number = {period_number}\", out_fields=\"period_number\", return_geometry=False, as_df=True)\n",
    "        \n",
    "        if not query_result.empty:\n",
    "            print(f\"Data found for period_number: {period_number}\")\n",
    "            break  # Exit loop when data is found\n",
    "        else:\n",
    "            print(f\"No data for period_number: {period_number}, trying previous period...\")\n",
    "            period_number -= 1  # Try the previous period\n",
    "\n",
    "if period_number is not None:\n",
    "    where_clauses.append(f\"period_number = {period_number}\")\n",
    "\n",
    "# Combine conditions or select all\n",
    "where_clause = \" AND \".join(where_clauses) if where_clauses else \"1=1\"\n",
    "\n",
    "# Query the feature table but exclude the ObjectId field\n",
    "fields = [f['name'] for f in feature_layer.properties.fields if f['name'].lower() != 'objectid']\n",
    "df = feature_layer.query(where=where_clause, out_fields=\",\".join(fields), return_geometry=False, as_df=True)\n",
    "\n",
    "# Rename 'people_affected' to 'people_exposed' if it exists\n",
    "df.rename(columns={'pop_affected': 'pop_exposed'}, inplace=True)\n",
    "\n",
    "# Determine filename components\n",
    "iso3_label = iso3 if iso3 else \"allcountries\"\n",
    "\n",
    "# If a period is selected, retrieve the biweekly_group value\n",
    "if period_number is not None and not df.empty:\n",
    "    biweekly_group = df['biweekly_group'].iloc[0].replace(\" \", \"_\").replace(\"/\", \"-\")  # Clean filename\n",
    "    file_name = f\"filtered_data_{iso3_label}_{biweekly_group}_{formatted_datetime}\"\n",
    "else:\n",
    "    file_name = f\"filtered_data_{iso3_label}_allperiods_{formatted_datetime}\"\n",
    "\n",
    "# Ensure output folder exists\n",
    "os.makedirs(output_location, exist_ok=True)\n",
    "\n",
    "# Define output file path\n",
    "file_path = os.path.join(output_location, file_name)\n",
    "\n",
    "# Save to chosen format\n",
    "if file_format.upper() == 'CSV':\n",
    "    df.to_csv(f\"{file_path}.csv\", index=False)\n",
    "    print(f\"Saved data as CSV: {file_path}.csv\")\n",
    "elif file_format.upper() == 'EXCEL':\n",
    "    df.to_excel(f\"{file_path}.xlsx\", index=False)\n",
    "    print(f\"Saved data as Excel: {file_path}.xlsx\")\n",
    "else:\n",
    "    print(\"Invalid file format. Please choose 'CSV' or 'Excel'.\")\n",
    "\n",
    "print(\"Process completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6021ae016671ea4ee51b821cf683f744f40429a54e6c6181c983710cf505a5e5"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
